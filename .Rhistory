################################
## Kanonicka korelace
#	korelace mezi dvema skupinami promennych
# pracujme s charakteristikami statu: osobni uspory, podil populace do 15 let,
#	podil populace nad 75 let, prijem na obyvatele, narust prijmu na obyvatele
# rozdelime promenne do skupin: populacni podily, ekonomicke charakteristiky
pop <- LifeCycleSavings[, 2:3]
oec <- LifeCycleSavings[, -(2:3)]
cancor(pop, oec)
# TODO
# vypocet kanonickych korelaci
#	na vystupu jsou kanonicke korelace (jejich pocet je stejny jako
#	pocet promennych v mensi skupine), koeficienty kanonickych promennych
#	prumery promennych
################################
## Diskriminační analýza
library(MASS)
# databaze o trech druzich kosatcu: Setosa (s), Versicolour (c), Virginica (v)
# mereny jsou 4 ukazatele: sepal length & width, petal length & width
#	kalisni a okvetni listek, vzdy delka a sirka
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),Sp = rep(c("s","c","v"), rep(50,3)))
# nahodny vyber 75 rostlin z cele databaze
train <- sample(1:150, 75) # 75 náhodných čísel v intervalu 1-150
table(Iris$Sp[train])
#tvorba trénovacích dat
# vstupni data do diskriminacni analyzy ... rostliny, u nichz presne zname druh
(z <- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train))
# linearni diskriminacni analyza
# vystup: vstupni (apriori) PRAVDĚPODOBNOSTI ... jake je ocekavane zastoupeni skupin v populaci
#	prumery promennych ve skupinach a koeficienty linearnich diskriminacnich funkci
predpovedi<-predict(z, Iris[-train, ])
predpovedi$x
# vysledne hodnoty diskriminacnich funkci
predpovedi$posterior
# pravdepodobnosti zarazeni do jednotlivych populaci
predpovedi$class
# na zaklade vytvorene klasifikacni funkce priradi nova mereni do skupin
#	vybere idealni skupinu + vypocte pravdepodobnosti s nimiz do jednotlivych skupin patri
table(Iris[-train,"Sp"],predpovedi$class)
# klasifikacni tabulka, jak dobre se trefil: v radcich skutecne hodnoty, ve sloupcich predikce
plot(predpovedi$x[,1],predpovedi$x[,2],pch=19,col=predpovedi$class,
main="Graf diskriminacnich funkci",xlab="LD1",ylab="LD2")
legend(9,2.2,legend=c(unique(predpovedi$class)),pch=19,col=1:3)
# graf ukazujici kvalitu klasifikace
################################
## Shlukova analyza
# budem delit americke staty do skupin na zaklade 4 ukazatelu: vrazdy, napadeni, populace, znasilneni
# hierarchicke clusterovani
hc <- hclust(dist(USArrests), "ave")
# average linkage
hc <- hclust(dist(USArrests))
# complete linkage
# vstupem je matice vzdalenosti jednotlivych bodu
plot(hc, hang = -1)
# nakresleni dendrogramu - postup, jak shlukuje
#	nejprve ma kazde pozorovani svou vlastni skupinu, a ty se pak spojuji do vetsich celku
#	mozny je i obraceny postup, tj. od jedne velke skupiny k mnoha malym
seg<-cutree(hc,k=4)
# rozdeli data do 4 skupin
table(seg)
rect.hclust(hc, k=4, border="red")
# zobrazi skupiny do grafu
tapply(USArrests$Murder,as.factor(seg),mean)
# spocita prumery za jednotlive shluky
# K-means clustering
require(graphics)
# prace s dvojrozmernymi daty
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x", "y")
# vygenerovani dat
(cl <- kmeans(x, 2))
# rozdeleni dat do dvou segmentu (pocet segmentu vybiram podle 'potreby')
# mohu zkusit vice seskupeni a porovnat je mezi sebou
plot(x, col = cl$cluster,pch=19)
# zakresleni dat rozdelenych do skupin
points(cl$centers, col = 1:2, pch = 8, cex=2,lwd=2)
# zakresleni stredu
gc()
gc()
library(MASS)
# knihovna s nastroji mnohorozmerne statistiky
library(MASS)
load("D:/PSM_TEACH/PSM_Teach/Ichs.RData")
data <- Ichs
data
Iris
data <- Iris
data <- Iris
# knihovna s nastroji mnohorozmerne statistiky
library(MASS)
data <- Iris
data <- iris3
data
iris <- iris3
df <- data.frame(rbind(iris[,,1],iris[,,2],iris[,,3]))
df
df <- data.frame(rbind(iris[,,1],iris[,,2],iris[,,3]))
df
df <- data.frame(rbind(iris[,,1],iris[,,2],iris[,,3]),Sp = rep(c("s","c","v"), rep(50,3)))
df
View(df)
len <- length(df)
len
len <- length(df[,1])
len
train_index <- sample(1:len,0.5*len)
train_data <- df[,train_index]
train_data <- df[train_index]
train_data <- df$Sp[train_index]
train_data
table(df$Sp[train_index])
#Model lda
model <- lda(Sp ~ ., df, prior=c(1,1,1)/3, subset = train_index)
c(1,1,1)/3
predict(model, df[-train_index])
predict(model, df[-train_index])$x
predict(model, df[-train_index,])
predict(model, df[-train_index,])$posterior
predict(model, df[-train_index,])$x #<- vysledky diskriminačni funkci
predict(model, df[-train_index,])$posterior
predict(z, Iris[-train, ])$class
predict(model, df[-train_index, ])$class
hat_skupiny <- predict(model, df[-train_index, ])$class #<- zařazené kupiny
table(cbind(df$Sp,hat_skupiny)
table(cbind(df$Sp,hat_skupiny))
table(cbind(df$Sp[-train,],hat_skupiny))
table(cbind(df$Sp[-train_index,],hat_skupiny))
table(df$Sp[-train_index,],hat_skupiny)
table(df[-train_index,Sp],hat_skupiny)
table(df[-train_index,"Sp"],hat_skupiny)
table(df[-train_index,]$Sp,hat_skupiny)
table(df[-train_index,]$Sp,hat_skupiny)
test_index <- df$Sp[-train_index]
test_index <- df[-train_index]
hat_skupiny <- predict(model, df[test_index, ])$class #<- zařazené kupiny
# Train indexy - 50% z df
train_index <- sample(1:len,0.5*len)
# Počty jednotlivých skupin
table(df$Sp[train_index])
model <- lda(Sp ~ ., df, prior=c(1,1,1)/3, subset = train_index)
predict(model, df[-train_index,])$x #<- vysledky diskriminačni funkci
predict(model, df[-train_index,])$posterior #<- Pst. pro zařazení do skupin
hat_skupiny <- predict(model, df[-train_index, ])$class #<- zařazené kupiny
# Klasifikačí tabulka -> validace
table(df[-train_index,]$Sp,hat_skupiny)
# Klasifikačí tabulka -> validace
table(df[-train_index,]$Sp,hat_skupiny)
accuracy <- 3/75
accuracy
accuracy = 1-accuracy
accuracy = 1-accuracy
accuracy
error <- 3/75
accuracy = 1-error
accuracy
summary(model)
summary(model)
df_vystup rbind(df,hat_skupiny)
df_vystup cbind(df,hat_skupiny)
df_vystup <- cbind(df,hat_skupiny)
df_vystup
plot(df_vystup$Sp,df_vystup$hat_skupiny)
plot(model$x[,1],model$x[,2])
plot(model$x[,1],model$x[,2], pch=19, col=model$class)
predpoved <- predict(model, df[-train_index,])
plot(predpoved$x[,1],predpoved$x[,2], pch=19, col=model$class)
plot(predpoved$x[,1],predpoved$x[,2], pch=19, col=predpoved$class)
plot(predpoved$x[,1],predpoved$x[,2], pch=19, col=predpoved$class, labels=predpoved$class)
plot(predpoved$x[,1],predpoved$x[,2], pch=19, col=predpoved$class)
## Shlukova analyza
dist(USArrests)
data <- dist(USArrests)
data <- dist(USArrestsm)
data <- dist(USArrests)
hc <- hclust(data, "ave")
plot(hc)
# Dendogram
plot(hc, hang=-1)
# Cut ve stromu
seg <- cuttree(hc,k=4)
# Cut ve stromu
seg <- cutree(hc,k=4)
# Cut ve stromu
seg <- cutree(hc,k=4)
seq
seg
rect.hclust(hc, k=4, border="red")
rect.hclust(hc, k=4, border="red")
# Cut ve stromu
seg <- cutree(hc,k=4)
data
data$ave
dist(USArrests)
data
data <- USArrests
data
data <- dist(data)
data <- dist(data)
data <- USArrests
data
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg)
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Murder,USArrests$UrbanPop, col=seg, pch=19)
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Murder,USArrests$UrbanPop, col=seg, pch=19)
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Murder,USArrests$UrbanPop, col=seg, pch=19)
plot(USArrests$Rape,USArrests$Assault, col=seg, pch=19)
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Murder,USArrests$UrbanPop, col=seg, pch=19)
plot(USArrests$Rape,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Murder,USArrests$UrbanPop, col=seg, pch=19)
# Segmenty v datech
plot(USArrests$Murder,USArrests$Assault, col=seg, pch=19)
plot(USArrests$Rape,USArrests$Assault, col=seg, pch=19)
#Škálování dat
USArrests.sc <- scale(USArrests)
View(USArrests.sc)
hc.sc <- hclust(dist(USArrests.sc), "ave")
plot(hc.sc, hang = -1)
seg.sc<-cutree(hc.sc,k=5)
plot(hc.sc, hang = -1)
seg.sc<-cutree(hc.sc,k=5)
table(seg,seg.sc)
plot(USArrests$Murder,USArrests$Assault,col=seg.sc,pch=19)
plot(USArrests$UrbanPop,USArrests$Rape,col=seg.sc,pch=19)
plot(USArrests$Murder,USArrests$Assault,col=seg.sc,pch=19)
plot(USArrests$UrbanPop,USArrests$Rape,col=seg.sc,pch=19)
# Vykreslení hlaních komponent
pc <-prcomp(USArrests.sc)
summary(pc)
# Vykreslení hlaních komponent
pc <-prcomp(USArrests.sc)$x
summary(pc)
pc
plot(pc[,1],pc[,2],col=seg.sc,pch=19)
plot(pc[,1],pc[,2],col=seg.sc,pch=19)
# Vykreslení hlaních komponent
pc <-prcomp(USArrests.sc)$x
pc
eigen(cor(USArrests.sc))/sum(eigen(cor(USArrests.sc)))
cumsum(eigen(cor(USArrests.sc)))/sum(eigen(cor(USArrests.sc)))
cumsum(eigen(cor(USArrests.sc))$values/sum(eigen(cor(USArrests.sc))$values))
# Vykreslení hlaních komponent
pc <-prcomp(USArrests.sc)$x
pc
plot(pc[,1],pc[,2],col=seg.sc,pch=19)
# [1] 0.6978994 0.8892514 0.9448109 0.9705376 0.9913370 1.0000000
factanal(cars2, factors=2)
factanal(USArrests.sc, factors=2)
factanal(USArrests.sc, factors=1)
cumsum(eigen(cor(USArrests.sc))$values/sum(eigen(cor(USArrests.sc))$values))
# V praxi se casteji pouziva metoda complete linkage
hc.sc2 <- hclust(dist(USArrests.sc))
plot(hc.sc2, hang = -1)
seg.sc2<-cutree(hc.sc2,k=4)
table(seg,seg.sc2)
table(seg.sc,seg.sc2)
plot(pc[,1],pc[,2],col=seg.sc2,pch=19)
plot(pc[,1],pc[,2],col=seg.sc2,pch=19)
plot(pc[,3],pc[,4],col=seg.sc2,pch=19)
rect.hclust(hc.sc2, k=4, border="red")
rect.hclust(hc.sc2, k=4, border="red")
plot(hc.sc2, hang = -1)
seg.sc2<-cutree(hc.sc2,k=4)
table(seg,seg.sc2)
table(seg.sc,seg.sc2)
rect.hclust(hc.sc2, k=4, border="red")
plot(pc[,1],pc[,2],col=seg.sc2,pch=19)
plot(pc[,3],pc[,4],col=seg.sc2,pch=19)
# je mozne vysledne segmenty popsat pomoci puvodnich promennych
tapply(USArrests$Murder,as.factor(seg.sc2),mean)
tapply(USArrests$Assault,as.factor(seg.sc2),mean)
tapply(USArrests$UrbanPop,as.factor(seg.sc2),mean)
tapply(USArrests$Rape,as.factor(seg.sc2),mean)
seg.sc2
# je mozne vysledne segmenty popsat pomoci puvodnich promennych
tapply(USArrests$Murder,as.factor(seg.sc2),mean)
# je mozne vysledne segmenty popsat pomoci puvodnich promennych
tapply(USArrests$Murder,as.factor(seg.sc2),mean)
tapply(USArrests$Assault,as.factor(seg.sc2),mean)
clear
# je mozne vysledne segmenty popsat pomoci puvodnich promennych
tapply(USArrests$Murder,as.factor(seg.sc2),mean)
tapply(USArrests$Assault,as.factor(seg.sc2),mean)
tapply(USArrests$UrbanPop,as.factor(seg.sc2),mean)
tapply(USArrests$Rape,as.factor(seg.sc2),mean)
#-----------------------------------------------------
###
#K-means clustering
require(graphics)
seg.km <- kmeans(USArrests.sc, 4)
table(seg.sc2,seg.km)
table(seg.sc2,seg.km$cluster)
plot(USArrests$Murder,USArrests$Assault,col=seg.km$cluster,pch=19)
plot(USArrests$UrbanPop,USArrests$Rape,col=seg.km$cluster,pch=19)
plot(pc[,1],pc[,2],col=seg.km$cluster,pch=19)
plot(USArrests$UrbanPop,USArrests$Rape,col=seg.km$cluster,pch=19)
plot(USArrests$Murder,USArrests$Assault,col=seg.km$cluster,pch=19)
seg.km$centers
data <- data("Crabs")
data <- data("crabs")
data
data("crabs")
crabs
data <- crabs[4:8,]
data
data <- crabs[,4:8]
data
crabs.km <- kmeans(data,4)
#Hierarchické clustering
crabs.hcl <- hcl(data, k =4)
#Hierarchické clustering
crabs.hcl <- hclust(dist(data), k=4)
#Hierarchické clustering
crabs.hcl <- hclust(dist(data))
plot(crabs.hcl)
rect.hclust(crabs.hcl, k=4, border="red")
crabs.reg <- cutree(crabs.hcl, k=4)
table(crabs.hcl,crabs.reg)
table(crabs.hcl,crabs.reg$cluster)
table(crabs.hcl,crabs.km$cluster)
data <- crabs[,4:8] #manipulace s daty 4-8 sloupec
data
# Kmeans -4
crabs.km <- kmeans(data,4)
#Hierarchické clustering
crabs.hcl <- hclust(dist(data))
plot(crabs.hcl)
rect.hclust(crabs.hcl, k=4, border="red")
# mám rozdělení do 4 skupin
crabs.reg <- cutree(crabs.hcl, k=4)
table(crabs.hcl,crabs.km$cluster)
table(crabs.hcl,crabs.km$cluster)
View(crabs.hcl)
View(crabs.hcl)
reg.km <- cutree(crabs.km, k=4)
# Kmeans -4
crabs.km <- kmeans(data,4)
reg.km <- cutree(crabs.km, k=4)
table(crabs.reg,crabs.km$cluster)
factanal(data, factors = 3)
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
#-----------------------------------------------------
### #K-means clustering - Crabs
data("crabs")
data <- crabs[,4:8] #manipulace s daty 4-8 sloupec
data
# Kmeans -4
crabs.km <- kmeans(data,4)
#Hierarchické clustering
crabs.hcl <- hclust(dist(data))
plot(crabs.hcl)
rect.hclust(crabs.hcl, k=4, border="red")
# mám rozdělení do 4 skupin
crabs.reg <- cutree(crabs.hcl, k=4)
table(crabs.reg,crabs.km$cluster)
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
factanal(data, factors = 2)
factanal(data, factors = 3)
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
## Analýza hlavních komponent
### Faktorová analýza
factanal(data, factors = 1)
## Analýza hlavních komponent
### Faktorová analýza
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
table(crabs.reg,crabs.km$cluster)
## Analýza hlavních komponent
### Faktorová analýza
factanal(data, factors = 2)
pca <- prcomp(data)
pca
summary(pca)
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
#Hierarchické clustering
crabs.hcl <- hclust(dist(data))
plot(crabs.hcl)
rect.hclust(crabs.hcl, k=4, border="red")
# mám rozdělení do 4 skupin
crabs.reg <- cutree(crabs.hcl, k=4)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
factanal(data, factors = 2)
pca <- prcomp(data)
summary(pca) #tady lze vidět, že první komponenta vysvětluje 98%, takže stačí jedna proměnná
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
summary(pca) #tady lze vidět, že první komponenta vysvětluje 98%, takže stačí jedna proměnná
data_filtered <- data [,1:2]
data_filtered
data_filtered <- data [,1:1]
data_filtered
data_filtered <- data [,1]
data_filtered
factanal(data, factors = 2)
cumsum(eigen(cor(data))$values/sum(eigen(cor(data))$values))
cluter2<- kmeans(data_filtered, k=2)
cluter2<- kmeans(data_filtered, 2)
summary(cluster2)
cluster2<- kmeans(data_filtered, 2)
summary(cluster2)
cluster2<- kmeans(data_filtered, 2)
cluster3<-hclust(dist(data_filtered))
data_filtered <- data [,1] #<- vezmeme jenom jendu komponentu
cluster2<- kmeans(data_filtered, 2)
cluster3<-hclust(dist(data_filtered))
cl3.cut <- cutree(cluster3, k=2)
table(cl3.cut,cluster2$cluster)
plot(cluster3)
rect.hclust(hcluster3, k=4, border="red")
plot(cluster3)
rect.hclust(hcluster3, k=2, border="red")
plot(cluster3)
rect.hclust(cluster3, k=2, border="red")
## Kanonicka korelace
#	korelace mezi dvema skupinami promennych
# pracujme s charakteristikami statu: osobni uspory, podil populace do 15 let,
#	podil populace nad 75 let, prijem na obyvatele, narust prijmu na obyvatele
# rozdelime promenne do skupin: populacni podily, ekonomicke charakteristiky
pop <- LifeCycleSavings[, 2:3]
oec <- LifeCycleSavings[, -(2:3)]
cancor(pop, oec)
## Kanonicka korelace
#	korelace mezi dvema skupinami promennych
# pracujme s charakteristikami statu: osobni uspory, podil populace do 15 let,
#	podil populace nad 75 let, prijem na obyvatele, narust prijmu na obyvatele
# rozdelime promenne do skupin: populacni podily, ekonomicke charakteristiky
pop <- LifeCycleSavings[, 2:3]
oec <- LifeCycleSavings[, -(2:3)]
cancor(pop, oec)
2+2
LifeCycleSavings
## Korespondencni analyza
#########################
## Korespondencni analyza
#	zpusob, jak graficky znazornit vztah mezi dvema kategorickymi promennymi
library(ca)
data("author")
# prodej knih v knihkupectvich
fit<-ca(author)
print(fit)			# zakladni vystupy
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
plot(fit) 			# zakladni graf
# body, ktere jsou k sobe blizko si jsou podobne
plot(fit, mass = TRUE, contrib = "absolute", map ="rowgreen", arrows = c(FALSE, TRUE))
data(smoke)
# fiktivni data o koureni ve firme
fit2 <- ca(smoke)
plot(fit2)
## Korespondencni analyza
#########################
## Korespondencni analyza
#	zpusob, jak graficky znazornit vztah mezi dvema kategorickymi promennymi
library(ca)
data("author")
# prodej knih v knihkupectvich
fit<-ca(author)
print(fit)			# zakladni vystupy
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
plot(fit) 			# zakladni graf
# body, ktere jsou k sobe blizko si jsou podobne
plot(fit, mass = TRUE, contrib = "absolute", map ="rowgreen", arrows = c(FALSE, TRUE))
data(smoke)
library(ca)
install.packages("ca")
library(ca)
data("author")
# prodej knih v knihkupectvich
fit<-ca(author)
print(fit)			# zakladni vystupy
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
library(ca)
data("author")
# prodej knih v knihkupectvich
fit<-ca(author)
print(fit)			# zakladni vystupy
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
plot(fit) 			# zakladni graf
library(ca)
data("author")
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
plot(fit) 			# zakladni graf
# body, ktere jsou k sobe blizko si jsou podobne
plot(fit, mass = TRUE, contrib = "absolute", map ="rowgreen", arrows = c(FALSE, TRUE))
data(smoke)
# fiktivni data o koureni ve firme
fit2 <- ca(smoke)
plot(fit2)
# oddeleni SE kouri nejmene a JM naopak nejvice
summary(fit2)
library(ca)
data("author")
# prodej knih v knihkupectvich
fit<-ca(author)
print(fit)			# zakladni vystupy
# chi-kvadrat, inertia, souradnice
summary(fit) 		# dalsi vystupy
View(cluster3)
